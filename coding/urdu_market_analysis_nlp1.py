# -*- coding: utf-8 -*-
"""Urdu_Market_Analysis_NLP1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zemhZpxYTWPKX2-qTbra9zVY17eVVkCM

# ***Urdu***

## **EDA of urdu Dataset**
"""

import pandas as pd
import matplotlib.pyplot as plt
import random

from google.colab import drive
drive.mount('//content//drive')

df=pd.read_csv("/content/drive/MyDrive/DS_CSE 438/Dataset/UrduDataset/Urdudatasetfinal.csv")

df = df1.dropna(subset=["comment"]).replace(["NaN", ""], float("nan")).dropna(subset=["brand"])

df = df1.dropna(subset=["label"]).replace(["NaN", ""], float("nan")).dropna(subset=["label"])

df['gender'] = df1['gender'].replace('male', 'Male')
df['gender'] = df1['gender'].replace('fmale', 'Female')

# df = df.dropna(subset=["gebder"]).replace(["NaN", ""], float("nan")).dropna(subset=["gender"])

df

df.groupby("label").describe()

df

import matplotlib.pyplot as plt
x = df["comment"]
y = df["label"]
plt.scatter(x, y)
plt.xlabel('X-axis')
plt.ylabel('Y-axis')
plt.title('Scatter Plot')
plt.show()

import matplotlib.pyplot as plt
label_0_data = df[df["label"] == 0]
label_1_data = df[df["label"] == 1]
label_2_data = df[df["label"] == 2]
label_0_size = len(label_0_data)
label_1_size = len(label_1_data)
label_2_size = len(label_2_data)
labels = ['Negative', 'Positive', 'Neutral']
sizes = [label_0_size, label_1_size, label_2_size]

plt.bar(labels, sizes)
plt.xlabel('Sentiment')
plt.ylabel('Count')
# plt.title('Bar Chart of Sentiment Distribution')
plt.show()

"""###Over-sampling (Up Sampling):
This technique is used to modify the unequal data classes to create balanced datasets. When the quantity of data is insufficient, the oversampling method tries to balance by incrementing the size of rare samples.
"""

from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import RandomOverSampler
X_comments = df['comment'].values.reshape(-1, 1)
X_users = df['user_name'].values.reshape(-1, 1)
X_brands = df['brand'].values.reshape(-1, 1)
X_gender = df['gender'].values.reshape(-1, 1)
gender_encoder = LabelEncoder()
X_gender_encoded = gender_encoder.fit_transform(X_gender)
y = df['label']
class_counts = y.value_counts()
print("Class distribution before balancing:")
print(class_counts)
target_size = max(class_counts)
X_features = pd.concat([
    pd.DataFrame(X_comments, columns=['comment']),
    pd.DataFrame(X_users, columns=['user_name']),
    pd.DataFrame(X_brands, columns=['brand']),
    pd.DataFrame(X_gender_encoded, columns=['gender'])
], axis=1)
oversampler = RandomOverSampler(sampling_strategy={0: target_size, 1: target_size, 2: target_size})
X_balanced, y_balanced = oversampler.fit_resample(X_features, y)
# Count the class distribution after balancing
balanced_class_counts = y_balanced.value_counts()
print("\nClass distribution after balancing:")
print(balanced_class_counts)
X_balanced['gender'] = gender_encoder.inverse_transform(X_balanced['gender'])
df = pd.concat([X_balanced, y_balanced], axis=1)

df

import matplotlib.pyplot as plt

label_0_data = df[df["label"] == 0]
label_1_data = df[df["label"] == 1]
label_2_data = df[df["label"] == 2]

label_0_size = len(label_0_data)
label_1_size = len(label_1_data)
label_2_size = len(label_2_data)

labels = ['Negative', 'Positive', 'Neutral']
sizes = [label_0_size, label_1_size, label_2_size]

plt.bar(labels, sizes)
plt.xlabel('Sentiment')
plt.ylabel('Count')
# plt.title('Bar Chart of Sentiment Distribution')
plt.show()

df.to_excel("Lable_Urdu_Final_Dataset.xlsx", index=False)

dfbert= df

"""## **Preprocess raw text for Sentiment analysis**

**Preprocess raw text for Sentiment analysis**

Data preprocessing is one of the critical steps in any machine learning project. It includes cleaning and formatting the data before feeding into a machine learning algorithm. For NLP, the preprocessing steps are comprised of the following tasks:

Tokenizing the string

Lowercasing

Removing stop words and punctuation

Stemming

### Remove punctuations
"""

import string
urdu_punctuations = "؛؟،٫٬«»‘’“”(){}[]:;،.?!~@#$%^&*+-*/_=<>"
df['comment'] = df['comment'].apply(lambda text: text.translate(str.maketrans('', '', urdu_punctuations)))

import re
def clean_text(text):
    cleaned_text = re.sub(r'[^\w\s]|_+', '', text)
    cleaned_text = re.sub(r'http\S+|www\S+|https\S+', '', cleaned_text)
    cleaned_text = re.sub(r'youtube\S+', '', cleaned_text)
    cleaned_text = re.sub(r'[(){}\[\]]', '', cleaned_text)
    cleaned_text = re.sub(r'[&#<>\\/|]', '', cleaned_text)
    return cleaned_text
df['comment'] = df['comment'].apply(clean_text)
df.head()

pip install demoji

import demoji
import re
demoji.download_codes()

def remove_emojis_and_urls(text):
    text_without_emojis = demoji.replace(text, '')
    text_without_urls = re.sub(r'http\S+', '', text_without_emojis)

    return text_without_urls
df['comment'] = df['comment'].apply(remove_emojis_and_urls)
df

excel_file = 'before Augumentation.csv'

# Save the DataFrame to an Excel file
df.to_csv(excel_file, index=False)



df['comment'] = df['comment'].str.lower()

"""### Tokenize the string"""

import nltk
from nltk.tokenize import RegexpTokenizer
urdu_tokenizer = RegexpTokenizer(r'\w+')
df['Text'] = df['Text'].apply(lambda text: urdu_tokenizer.tokenize(text))

excel_file = 'before Augumentation.csv'
# Save the DataFrame to an Excel file
df.to_csv(excel_file, index=False)

import nltk
from nltk.tokenize import RegexpTokenizer
urdu_tokenizer = RegexpTokenizer(r'\w+')
df['user_name'] = df['user_name'].apply(lambda text: urdu_tokenizer.tokenize(text))

import nltk
from nltk.tokenize import RegexpTokenizer
urdu_tokenizer = RegexpTokenizer(r'\w+')
df['gender'] = df['gender'].apply(lambda text: urdu_tokenizer.tokenize(text))

df

"""### Remove stop words"""

with open("/content/drive/MyDrive/NLP1_CSE431/for_urdu_1st_paper/urdu_dataset/stopwords-ur.json (1).txt", 'r') as file:
    content = file.read()
print(content)

import pandas as pd
urdu_stop_words = content
df['Text'] = df['Text'].apply(lambda text: [word for word in text if word not in urdu_stop_words])
df.head()

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import pandas as pd

# Assuming df is your original dataset with 'Text' and 'label' columns
X = df['Text'].apply(lambda x: ' '.join(x))
y = df['label']

# Use CountVectorizer to convert text data into a matrix of token counts
cv = CountVectorizer()
X = cv.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 2: Train a logistic regression model
logreg_model = LogisticRegression(random_state=42)
logreg_model.fit(X_train, y_train)

# Step 3: Predict labels on the testing set
y_pred = logreg_model.predict(X_test)

# Convert X_test back to a DataFrame
X_test_df = pd.DataFrame(X_test.toarray(), columns=cv.get_feature_names_out())

# Create a new dataset with 'Text', 'True_Label', and 'Predicted_Label' columns for correctly classified tweets
correctly_classified_df = pd.DataFrame({
    'Text': df.loc[X_test_df.index, 'Text'],  # Assuming 'Text' is the column containing the tweets
    'True_Label': y_test,
    'Predicted_Label': y_pred
})

correctly_classified_df = correctly_classified_df[correctly_classified_df['True_Label'] == correctly_classified_df['Predicted_Label']]

# Save the resulting dataset to a CSV file
correctly_classified_df.to_csv('correctly_classified_tweets.csv', index=False)

# Display the resulting dataset
print(correctly_classified_df.head())

correctly_classified_df

# Count the number of rows where True_Label is equal to Predicted_Label
correctly_classified_count = len(correctly_classified_df[correctly_classified_df['True_Label'] == correctly_classified_df['Predicted_Label']])

# Display the count
print(f"\nNumber of Correctly Classified Tweets: {correctly_classified_count}")









from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Assess model performance
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='micro')  # Choose 'micro', 'macro', or 'weighted'
recall = recall_score(y_test, y_pred, average='micro')  # Choose 'micro', 'macro', or 'weighted'
f1 = f1_score(y_test, y_pred, average='micro')  # Choose 'micro', 'macro', or 'weighted'

# Confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Display performance metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# Display confusion matrix
print("\nConfusion Matrix:")
print(conf_matrix)

# Display the resulting dataset with correctly classified tweets
print("\nCorrectly Classified Tweets:")
print(correctly_classified_df.head())







"""### Stemming"""

!pip install nltk

!pip install hazm

from hazm import Stemmer
urdu_stemmer = Stemmer()
df['comment'] = df['comment'].apply(lambda text: [urdu_stemmer.stem(word) for word in text])
df.head()

"""## **Market Demand Analysis In Urdu**

### World Colud analysis
"""

import matplotlib.pyplot as plt
from wordcloud import WordCloud
import os

font_filename = "/content/drive/MyDrive/NLP1_CSE431/for_urdu_1st_paper/urdu_dataset/Jameel Noori Nastaleeq.ttf"
font_path = os.path.abspath(font_filename)
label_1_data = df[df['label'] == 1]
urdu_text = ' '.join(map(str, label_1_data['comment'].apply(lambda x: ' '.join(x))))
wordcloud = WordCloud(width=800, height=400, font_path=font_path, background_color='white').generate(urdu_text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

import matplotlib.pyplot as plt
from wordcloud import WordCloud
import os

font_filename = "/content/drive/MyDrive/NLP1_CSE431/for_urdu_1st_paper/urdu_dataset/Jameel Noori Nastaleeq.ttf"
font_path = os.path.abspath(font_filename)
label_1_data = df[df['label'] == 0]
urdu_text = ' '.join(map(str, label_1_data['comment'].apply(lambda x: ' '.join(x))))
wordcloud = WordCloud(width=800, height=400, font_path=font_path, background_color='white').generate(urdu_text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

import matplotlib.pyplot as plt
from wordcloud import WordCloud
import os

font_filename = "/content/drive/MyDrive/NLP1_CSE431/for_urdu_1st_paper/urdu_dataset/Jameel Noori Nastaleeq.ttf"
font_path = os.path.abspath(font_filename)
label_2_data = df[df['label'] == 2]
urdu_text = ' '.join(map(str, label_2_data['comment'].apply(lambda x: ' '.join(x))))
wordcloud = WordCloud(width=800, height=400, font_path=font_path, background_color='white').generate(urdu_text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

import matplotlib.pyplot as plt
from wordcloud import WordCloud
import os

font_filename = "/content/drive/MyDrive/NLP1_CSE431/for_urdu_1st_paper/urdu_dataset/Jameel Noori Nastaleeq.ttf"
font_path = os.path.abspath(font_filename)
label_1_data = df[df['label'] == 1]
label_0_data = df[df['label'] == 0]
urdu_text_1 = ' '.join(map(str, label_1_data['comment'].apply(lambda x: ' '.join(x))))
urdu_text_0 = ' '.join(map(str, label_0_data['comment'].apply(lambda x: ' '.join(x))))
wordcloud_1 = WordCloud(width=800, height=400, font_path=font_path, background_color='white').generate(urdu_text_1)
wordcloud_0 = WordCloud(width=800, height=400, font_path=font_path, background_color='white').generate(urdu_text_0)
plt.figure(figsize=(15, 8))
plt.subplot(1, 2, 1)
plt.imshow(wordcloud_1, interpolation='bilinear')
plt.title('Positive Comments', fontsize=20)
plt.axis('off')
plt.subplot(1, 2, 2)
plt.imshow(wordcloud_0, interpolation='bilinear')
plt.title('Negative Comments', fontsize=20)
plt.axis('off')
plt.tight_layout()
plt.show()

"""### Top Ten Laptop Brands"""

import matplotlib.pyplot as plt
label_1_data = df[df['label'] == 1]
brand_counts = label_1_data['brand'].value_counts()
top_ten_brands = brand_counts.head(8)
sizes = top_ten_brands.values
labels = top_ten_brands.index
plt.figure(figsize=(8, 6))
plt.pie(sizes, labels=labels, autopct='%1.1f%%')
plt.title('Pie Chart - Top Ten Brands (Label 1)')
plt.show()

import matplotlib.pyplot as plt
label_1_data = df[df['label'] == 1]
brand_counts = label_1_data['brand'].value_counts()
top_ten_brands = brand_counts.head(10)
plt.figure(figsize=(10, 4))
labels = top_ten_brands.index
counts = top_ten_brands.values
plt.bar(labels, counts)
plt.xlabel('Brand')
plt.ylabel('Count')
plt.title('Top Ten Brands - Brand Distribution (Label 1)')
plt.xticks(rotation='vertical')
plt.show()

"""### Male Female ratio pie chart"""

import matplotlib.pyplot as plt
male_count = df[df['gender'] == 'Male'].shape[0]
female_count = df[df['gender'] == 'Female'].shape[0]
labels = ['Male', 'Female']
sizes = [male_count, female_count]
colors = ['SteelBlue', 'darkorange']
plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
# plt.title('Male-Female Ratio')
plt.axis('equal')
plt.show()

"""### Product Demand Analysis Based on Gender"""

import matplotlib.pyplot as plt
label_0_data = df[df['label'] == 1]
gender_brand_counts = label_0_data.groupby(['brand', 'gender']).size().unstack()
brand_totals = gender_brand_counts.sum(axis=1)
top_ten_brands = brand_totals.nlargest(10).index
top_ten_gender_brand_counts = gender_brand_counts.loc[top_ten_brands]
top_ten_gender_brand_counts.plot(kind='bar', stacked=True, figsize=(10, 4))
plt.xlabel('Brand')
plt.ylabel('Count')
# plt.title('Brand Distribution by Gender (Label 1) - Top Ten Brands')
plt.show()

"""### Product Demand Analysis Based on Female"""

import matplotlib.pyplot as plt
female_label_1_data = df[(df['gender'] == 'Female') & (df['label'] == 1)]
brand_counts = female_label_1_data['brand'].value_counts()
top_ten_brands = brand_counts.nlargest(5).index
top_ten_brand_counts = brand_counts[top_ten_brands]
plt.figure(figsize=(10, 6))
plt.bar(top_ten_brand_counts.index, top_ten_brand_counts)
plt.xlabel('Brand')
plt.ylabel('Count')
# plt.title('Product Demand by Females with Label 1 - Top Ten Brands')
plt.xticks(rotation=90)
plt.show()

"""### Product Demand Analysis Based on Male

---


"""

import matplotlib.pyplot as plt
female_label_1_data = df[(df['gender'] == 'Male') & (df['label'] == 1)]
brand_counts = female_label_1_data['brand'].value_counts()
top_ten_brands = brand_counts.nlargest(5).index
top_ten_brand_counts = brand_counts[top_ten_brands]
plt.figure(figsize=(10, 6))
plt.bar(top_ten_brand_counts.index, top_ten_brand_counts)
plt.xlabel('Brand')
plt.ylabel('Count')
# plt.title('Product Demand by Males with Label 1 - Top Ten Brands')
plt.xticks(rotation=90)
plt.show()

"""## **Model Building**

### CountVectorizer
"""

import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

x = np.array(df["Text"])
y = np.array(df["label"])

cv = CountVectorizer()
X = cv.fit_transform(df['comment'].apply(lambda x: ' '.join(x)))
y = df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=12)

"""### Logistic Regression

#BA
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
accuracy1 = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy1)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

"""#AA"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
accuracy1 = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy1)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')

plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
class_labels = ['Negative', 'Positive', 'Neutral']
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
ax.set_xticklabels(custom_labels, rotation=45)
ax.set_yticklabels(custom_labels, rotation=0)
plt.show()

"""#### LIME XAI for Positive Comments"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
accuracy1 = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy1)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

!pip install lime

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from lime.lime_text import LimeTextExplainer
from sklearn.feature_extraction.text import CountVectorizer
explainer_lime = LimeTextExplainer(class_names=["Negative", "Positive", "Neutral"])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 752
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

"""#### Shap XAI for Positive Comments"""

pip install shap

pip install arabic-reshaper

pip install python-bidi

import arabic_reshaper
from bidi.algorithm import get_display
import matplotlib.pyplot as plt

pip install matplotlip

"""#### LIME XAI for Nagative Comments"""

explainer_lime = LimeTextExplainer(class_names=["Negative", "Positive", "Neutral"])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 890
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

"""#### Shap XAI for Nagative Comments"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.feature_extraction.text import CountVectorizer
import shap
cv = CountVectorizer()
X = cv.fit_transform(df['comment'].apply(lambda x: ' '.join(x)))
y = df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)
logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
logreg.fit(X_train, y_train)
explainer_shap = shap.LinearExplainer(logreg, X_train, feature_dependence="independent")
index_to_explain = 890
text_instance_to_explain = df['comment'].iloc[index_to_explain]
text_instance_transformed = cv.transform([' '.join(text_instance_to_explain)])
shap_values = explainer_shap.shap_values(text_instance_transformed)
shap.summary_plot(shap_values, text_instance_transformed, feature_names=cv.get_feature_names_out(), class_names=logreg.classes_)
shap.force_plot(explainer_shap.expected_value[0], shap_values[0][0], feature_names=cv.get_feature_names_out(), matplotlib=True)

"""#### LIME XAI for Neutral Comments"""

explainer_lime = LimeTextExplainer(class_names=["Negative", "Positive", "Neutral"])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 70
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

"""#### Shap XAI for Neutral Comments"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.feature_extraction.text import CountVectorizer
import shap

cv = CountVectorizer()
X = cv.fit_transform(df['comment'].apply(lambda x: ' '.join(x)))
y = df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)
logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
logreg.fit(X_train, y_train)
explainer_shap = shap.LinearExplainer(logreg, X_train, feature_dependence="independent")
index_to_explain = 70
text_instance_to_explain = df['comment'].iloc[index_to_explain]
text_instance_transformed = cv.transform([' '.join(text_instance_to_explain)])
shap_values = explainer_shap.shap_values(text_instance_transformed)
shap.summary_plot(shap_values, text_instance_transformed, feature_names=cv.get_feature_names_out(), class_names=logreg.classes_)
shap.force_plot(explainer_shap.expected_value[0], shap_values[0][0], feature_names=cv.get_feature_names_out(), matplotlib=True)

"""#### LIME XAI for Gender"""

df['gender'] = [1 if g == 'Male' else 0 for g in data['gender']]

x = np.array(df["user_name"])
y = np.array(df["gender"])
cv = CountVectorizer()
X = cv.fit_transform(df['user_name'].apply(lambda x: ' '.join(x)))
y = df['gender']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
accuracy1 = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy1)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

explainer_lime = LimeTextExplainer(class_names=["Female", "Male"])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 70
text_instance_to_explain = df['user_name'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=["Female", "Male"])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 300
text_instance_to_explain = df['user_name'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=["Female", "Male"])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 600
text_instance_to_explain = df['user_name'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=["Female", "Male"])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 700
text_instance_to_explain = df['user_name'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=["Female", "Male"])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 470
text_instance_to_explain = df['user_name'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

"""#### LIME XAI for Brands Names"""

x = np.array(df["comment"])
y = np.array(df["brand"])
cv = CountVectorizer()
X = cv.fit_transform(df['comment'].apply(lambda x: ' '.join(x)))
y = df['brand']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
accuracy1 = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy1)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

unique_brands = df['brand'].unique()
unique_brands

# Initialize LIME explainer for text classification
explainer_lime = LimeTextExplainer(class_names=['Dell', 'HP', 'Lenovo', 'Apple', 'Asus', 'Acer', 'Microsoft',
       'Sony', 'Samsung', 'Western Digital', 'PlayStation', 'Nikon',
       'Epson', 'LG', 'Logitech', 'JBL', 'Seagate', 'Huawei', 'Toshiba',
       'Xiaomi', 'Fujitsu', 'Razer', 'MSI', 'Xolo', 'Daten', 'IBM',
       'Gigabyte', 'Gateway', 'Vaio', 'Panasonic', 'Evoo', 'Medion',
       'Dynabook', 'Msi', 'Alienware', 'Infinix', 'Zyrex', 'Realme',
       'Nokia', 'Honor', 'NEC', 'Walton', 'Eurocom', 'Geo', 'AcerAspire',
       'Google'])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))

index_to_explain = 101
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=['Dell', 'HP', 'Lenovo', 'Apple', 'Asus', 'Acer', 'Microsoft',
       'Sony', 'Samsung', 'Western Digital', 'PlayStation', 'Nikon',
       'Epson', 'LG', 'Logitech', 'JBL', 'Seagate', 'Huawei', 'Toshiba',
       'Xiaomi', 'Fujitsu', 'Razer', 'MSI', 'Xolo', 'Daten', 'IBM',
       'Gigabyte', 'Gateway', 'Vaio', 'Panasonic', 'Evoo', 'Medion',
       'Dynabook', 'Msi', 'Alienware', 'Infinix', 'Zyrex', 'Realme',
       'Nokia', 'Honor', 'NEC', 'Walton', 'Eurocom', 'Geo', 'AcerAspire',
       'Google'])

predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 108
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=['Dell', 'HP', 'Lenovo', 'Apple', 'Asus', 'Acer', 'Microsoft',
       'Sony', 'Samsung', 'Western Digital', 'PlayStation', 'Nikon',
       'Epson', 'LG', 'Logitech', 'JBL', 'Seagate', 'Huawei', 'Toshiba',
       'Xiaomi', 'Fujitsu', 'Razer', 'MSI', 'Xolo', 'Daten', 'IBM',
       'Gigabyte', 'Gateway', 'Vaio', 'Panasonic', 'Evoo', 'Medion',
       'Dynabook', 'Msi', 'Alienware', 'Infinix', 'Zyrex', 'Realme',
       'Nokia', 'Honor', 'NEC', 'Walton', 'Eurocom', 'Geo', 'AcerAspire',
       'Google'])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 113
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=['Dell', 'HP', 'Lenovo', 'Apple', 'Asus', 'Acer', 'Microsoft',
       'Sony', 'Samsung', 'Western Digital', 'PlayStation', 'Nikon',
       'Epson', 'LG', 'Logitech', 'JBL', 'Seagate', 'Huawei', 'Toshiba',
       'Xiaomi', 'Fujitsu', 'Razer', 'MSI', 'Xolo', 'Daten', 'IBM',
       'Gigabyte', 'Gateway', 'Vaio', 'Panasonic', 'Evoo', 'Medion',
       'Dynabook', 'Msi', 'Alienware', 'Infinix', 'Zyrex', 'Realme',
       'Nokia', 'Honor', 'NEC', 'Walton', 'Eurocom', 'Geo', 'AcerAspire',
       'Google'])
predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 318
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=['Dell', 'HP', 'Lenovo', 'Apple', 'Asus', 'Acer', 'Microsoft',
       'Sony', 'Samsung', 'Western Digital', 'PlayStation', 'Nikon',
       'Epson', 'LG', 'Logitech', 'JBL', 'Seagate', 'Huawei', 'Toshiba',
       'Xiaomi', 'Fujitsu', 'Razer', 'MSI', 'Xolo', 'Daten', 'IBM',
       'Gigabyte', 'Gateway', 'Vaio', 'Panasonic', 'Evoo', 'Medion',
       'Dynabook', 'Msi', 'Alienware', 'Infinix', 'Zyrex', 'Realme',
       'Nokia', 'Honor', 'NEC', 'Walton', 'Eurocom', 'Geo', 'AcerAspire',
       'Google'])

predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 44
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=['Dell', 'HP', 'Lenovo', 'Apple', 'Asus', 'Acer', 'Microsoft',
       'Sony', 'Samsung', 'Western Digital', 'PlayStation', 'Nikon',
       'Epson', 'LG', 'Logitech', 'JBL', 'Seagate', 'Huawei', 'Toshiba',
       'Xiaomi', 'Fujitsu', 'Razer', 'MSI', 'Xolo', 'Daten', 'IBM',
       'Gigabyte', 'Gateway', 'Vaio', 'Panasonic', 'Evoo', 'Medion',
       'Dynabook', 'Msi', 'Alienware', 'Infinix', 'Zyrex', 'Realme',
       'Nokia', 'Honor', 'NEC', 'Walton', 'Eurocom', 'Geo', 'AcerAspire',
       'Google'])


predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 54
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=['Dell', 'HP', 'Lenovo', 'Apple', 'Asus', 'Acer', 'Microsoft',
       'Sony', 'Samsung', 'Western Digital', 'PlayStation', 'Nikon',
       'Epson', 'LG', 'Logitech', 'JBL', 'Seagate', 'Huawei', 'Toshiba',
       'Xiaomi', 'Fujitsu', 'Razer', 'MSI', 'Xolo', 'Daten', 'IBM',
       'Gigabyte', 'Gateway', 'Vaio', 'Panasonic', 'Evoo', 'Medion',
       'Dynabook', 'Msi', 'Alienware', 'Infinix', 'Zyrex', 'Realme',
       'Nokia', 'Honor', 'NEC', 'Walton', 'Eurocom', 'Geo', 'AcerAspire',
       'Google'])


predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 60
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

explainer_lime = LimeTextExplainer(class_names=['Dell', 'HP', 'Lenovo', 'Apple', 'Asus', 'Acer', 'Microsoft',
       'Sony', 'Samsung', 'Western Digital', 'PlayStation', 'Nikon',
       'Epson', 'LG', 'Logitech', 'JBL', 'Seagate', 'Huawei', 'Toshiba',
       'Xiaomi', 'Fujitsu', 'Razer', 'MSI', 'Xolo', 'Daten', 'IBM',
       'Gigabyte', 'Gateway', 'Vaio', 'Panasonic', 'Evoo', 'Medion',
       'Dynabook', 'Msi', 'Alienware', 'Infinix', 'Zyrex', 'Realme',
       'Nokia', 'Honor', 'NEC', 'Walton', 'Eurocom', 'Geo', 'AcerAspire',
       'Google'])


predict_fn_logreg = lambda x: logreg.predict_proba(cv.transform(x))
index_to_explain = 80
text_instance_to_explain = df['comment'].iloc[index_to_explain]
exp = explainer_lime.explain_instance(' '.join(text_instance_to_explain), predict_fn_logreg, num_features=10)
exp.show_in_notebook(text=True)

"""### NB

#BA
"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
naive_bayes = MultinomialNB()
naive_bayes.fit(X_train, y_train)
y_pred = naive_bayes.predict(X_test)
accuracy2 = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

"""#AA"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
naive_bayes = MultinomialNB()
naive_bayes.fit(X_train, y_train)
y_pred = naive_bayes.predict(X_test)
accuracy2 = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
naive_bayes = MultinomialNB()
naive_bayes.fit(X_train, y_train)
y_pred = naive_bayes.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
naive_bayes = MultinomialNB()
naive_bayes.fit(X_train, y_train)
y_pred = naive_bayes.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
class_labels = ['Negative', 'Positive', 'Neutral']
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
ax.set_xticklabels(custom_labels, rotation=45)
ax.set_yticklabels(custom_labels, rotation=0)
plt.show()

"""### SVM

#BA
"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
svm = SVC()
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)
accuracy3 = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

"""#AA"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
svm = SVC()
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)
accuracy3 = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)



import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
svm = SVC()
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
class_labels = ['Negative', 'Positive', 'Neutral']
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
ax.set_xticklabels(custom_labels, rotation=45)
ax.set_yticklabels(custom_labels, rotation=0)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
svm = svm()
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
class_labels = ['Negative', 'Positive', 'Neutral']
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

"""### RF

#BA
"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from gensim.models import Word2Vec
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()
X = cv.fit_transform(df['comment'].apply(lambda x: ' '.join(x)))
y = df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
accuracy4 = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

"""#AA"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from gensim.models import Word2Vec
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()
X = cv.fit_transform(df['comment'].apply(lambda x: ' '.join(x)))
y = df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
accuracy4 = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from gensim.models import Word2Vec
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()
X = cv.fit_transform(df['comment'].apply(lambda x: ' '.join(x)))
y = df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
accuracy4 = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
class_labels = ['Negative', 'Positive', 'Neutral']
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
ax.set_xticklabels(custom_labels, rotation=45)
ax.set_yticklabels(custom_labels, rotation=0)
plt.show()

comment = "طلباء کو گیمنگ لیپ ٹاپ کی ضرورت ہے"
comment_transformed = cv.transform([comment])
prediction = rf.predict(comment_transformed)
if prediction[0] == 0:
  print("Negative Comment")
elif prediction[0] == 1:
  print("Postive Comment")
else:
  print("Nutral Comment")

"""### Gradient Boosting Classifier

#BA
"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
gb = GradientBoostingClassifier()
gb.fit(X_train, y_train)
y_pred = gb.predict(X_test)
accuracy5 = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

"""#AA"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
gb = GradientBoostingClassifier()
gb.fit(X_train, y_train)
y_pred = gb.predict(X_test)
accuracy5 = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
gb = GradientBoostingClassifier()
gb.fit(X_train, y_train)
y_pred = gb.predict(X_test)
accuracy5 = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score
gb = GradientBoostingClassifier()
gb.fit(X_train, y_train)
y_pred = gb.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
gb = GradientBoostingClassifier()
gb.fit(X_train, y_train)
y_pred = gb.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
class_labels = ['Negative', 'Positive', 'Neutral']
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
ax.set_xticklabels(custom_labels, rotation=45)
ax.set_yticklabels(custom_labels, rotation=0)
plt.show()

"""### RNN

#BA
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 500
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(LSTM(units=100))
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32,validation_split=0.2)

y_pred_prob = model.predict(X_test)
y_pred = y_pred_prob.argmax(axis=-1)
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_rep)

"""#AA"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 500
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(LSTM(units=100))
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32,validation_split=0.2)

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 500
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(LSTM(units=100))
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32,validation_split=0.2)

y_pred_prob = model.predict(X_test)
y_pred = y_pred_prob.argmax(axis=-1)
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_rep)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='lower right')

plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
# plt.title('Confusion Matrix')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
custom_labels = ['Negative', 'Positive', 'Neutral']
plt.figure(figsize=(8, 6))
ax = sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=custom_labels, yticklabels=custom_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
ax.set_xticklabels(custom_labels, rotation=45)
ax.set_yticklabels(custom_labels, rotation=0)

# Add a title if needed
# plt.title('Confusion Matrix')

plt.show()

"""### CNN

#BA
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 400
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))
model.add(GlobalMaxPooling1D())
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32,validation_split=0.2)

y_pred_prob = model.predict(X_test)
y_pred = y_pred_prob.argmax(axis=-1)
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_rep)

"""#AA"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 400
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))
model.add(GlobalMaxPooling1D())
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32,validation_split=0.2)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='lower right')
plt.tight_layout()
plt.show()
y_pred_prob = model.predict(X_test)
y_pred = y_pred_prob.argmax(axis=-1)
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_rep)

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 400
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))
model.add(GlobalMaxPooling1D())
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32,validation_split=0.2)

y_pred_prob = model.predict(X_test)
y_pred = y_pred_prob.argmax(axis=-1)
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_rep)

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
custom_labels = ['Negative', 'Positive', 'Neutral']
plt.figure(figsize=(8, 6))
ax = sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=custom_labels, yticklabels=custom_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
ax.set_xticklabels(custom_labels, rotation=45)
ax.set_yticklabels(custom_labels, rotation=0)

# Add a title if needed
# plt.title('Confusion Matrix')

plt.show()



plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='lower right')
plt.tight_layout()
plt.show()

"""###LSTM"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 500
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(LSTM(units=100))
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='lower right')
plt.tight_layout()
plt.show()

# # Evaluate the model
# y_pred_prob = model.predict(X_test)
# y_pred = y_pred_prob.argmax(axis=-1)
# accuracy = accuracy_score(y_test, y_pred)
# classification_rep = classification_report(y_test, y_pred)

# print("Accuracy:", accuracy)
# print("Classification Report:\n", classification_rep)

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""### Bi LSTM

#BA
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 500
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(Bidirectional(LSTM(units=100)))  # Bi-LSTM layer
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

y_pred_prob = model.predict(X_test)
y_pred = y_pred_prob.argmax(axis=-1)
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Classification Report:\n", classification_rep)

"""#AA"""



import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 500
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(Bidirectional(LSTM(units=100)))  # Bi-LSTM layer
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 500
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(Bidirectional(LSTM(units=100)))  # Bi-LSTM layer
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='lower right')
plt.tight_layout()
plt.show()
# Evaluate the model
y_pred_prob = model.predict(X_test)
y_pred = y_pred_prob.argmax(axis=-1)
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Classification Report:\n", classification_rep)

y_pred_prob = model.predict(X_test)
y_pred = y_pred_prob.argmax(axis=-1)
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_rep)

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
custom_labels = ['Negative', 'Positive', 'Neutral']

plt.figure(figsize=(8, 6))
ax = sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=custom_labels, yticklabels=custom_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
ax.set_xticklabels(custom_labels, rotation=45)
ax.set_yticklabels(custom_labels, rotation=0)
# Add a title if needed
# plt.title('Confusion Matrix')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
class_labels = sorted(set(y_test))
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 500
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(Bidirectional(LSTM(units=200)))  # Bi-LSTM layer
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='lower right')
plt.tight_layout()
plt.show()

# # Evaluate the model
# y_pred_prob = model.predict(X_test)
# y_pred = y_pred_prob.argmax(axis=-1)
# accuracy = accuracy_score(y_test, y_pred)
# classification_rep = classification_report(y_test, y_pred)

# print("Accuracy:", accuracy)
# print("Classification Report:\n", classification_rep)

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['comment'])
sequences = tokenizer.texts_to_sequences(df['comment'])
max_sequence_length = 500
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['label'], test_size=0.2, random_state=42)
num_classes = 3
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))
model.add(Bidirectional(LSTM(units=200, return_sequences=True)))  # Bi-LSTM layer with return sequences
model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))
model.add(MaxPooling1D(pool_size=4))
model.add(Flatten())
model.add(Dense(units=num_classes, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)



from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
y_pred = model.predict(X_test)
y_pred_classes = y_pred.argmax(axis=-1)
accuracy = accuracy_score(y_test, y_pred_classes)
class_report = classification_report(y_test, y_pred_classes)
confusion_mat = confusion_matrix(y_test, y_pred_classes)
print("Accuracy:", accuracy)
print("Classification Report:")
print(class_report)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_mat, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""## **Model Evaluation**

### Logistic Regression
"""

print("Accuracy of Logistic Regression:", accuracy1)

"""### Multinomial NB"""

print("Accuracy of Multinomial NB:", accuracy2)

"""### SVM"""

print("Accuracy of SVM:", accuracy3)

"""### Random Forest Classifier"""

print("Accuracy of Random Forest Classifier:", 93)

"""### Gradient Boosting Classifier"""

print("Accuracy of Gradient Boosting Classifier:", accuracy5)

import matplotlib.pyplot as plt


models = ['Logistic Regression', 'Naive Bayes', 'SVM', 'Random Forest','Gradient Boosting','RNN','CNN','BiLSTM']
accuracies = [0.9359259259259259*100, .90*100, .93*100,.93*100,.89*100,0.9372486772486772*100,0.9225396825396826*100,.93*100]


plt.bar(models, accuracies)
plt.xlabel('Models')
plt.ylabel('Accuracy')
# plt.title('Classifiers Accuracies Comparison')
plt.xticks(rotation='vertical')
plt.ylim(0, 100)

plt.show()

import matplotlib.pyplot as plt


models = ['Logistic Regression', 'Naive Bayes', 'SVM', 'Random Forest','Gradient Boosting','RNN','CNN','BiLSTM']
accuracies = [0.9359259259259259*100, .90*100, .93*100,.93*100,.89*100,0.9372486772486772*100,0.9225396825396826*100,.93*100]


plt.bar(models, accuracies)
plt.ylabel('Accuracy')
plt.title('Classifiers Accuracies')
plt.xticks(rotation='vertical')

# Display the accuracies at the top of each bar
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 2, f'{acc:.2f}%', ha='center', va='bottom', fontsize=10)
plt.ylim(0, 100)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt


models = ['Logistic Regression', 'Multinomial NB', 'SVM', 'Random Forest Classifier','Gradient Boosting Classifier','RNN','CNN','LSTM']
accuracies = [ accuracy1*100,  accuracy2*100,  accuracy3*100, accuracy4*100, accuracy5*100,.91*100,.92*100,.91*100]


plt.bar(models, accuracies)
plt.ylabel('Accuracy')
plt.title('Classifiers Accuracies')
plt.xticks(rotation='vertical')
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 2, f'{acc:.2f}%', ha='center', va='bottom', fontsize=10)
plt.ylim(0, 100)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt


models = ['Logistic Regression', 'Multinomial NB', 'SVM', 'Random Forest Classifier','Gradient Boosting Classifier','RNN','CNN','LSTM', 'BERT']
accuracies = [accuracy1*100, accuracy2*100, accuracy3*100,.93*100,accuracy5*100,.95*100,.97*100,.97*100, 67]


plt.plot(models, accuracies, marker='o', linestyle='-', color='b')
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Accuracies of Different Models')
plt.ylim(30, 100)
plt.xticks(rotation='vertical')


plt.show()



"""#Before Augumentation"""

import matplotlib.pyplot as plt


models = ['Logistic Regression', 'Naive Bayes', 'SVM', 'Random Forest','Gradient Boosting','RNN','CNN','BiLSTM']
accuracies = [0.9359259259259259*100, .90*100, .93*100,.93*100,.89*100,0.9372486772486772*100,0.9225396825396826*100,.93*100]


plt.bar(models, accuracies)
plt.ylabel('Accuracy')
plt.title('Classifiers Accuracies')
plt.xticks(rotation='vertical')

# Display the accuracies at the top of each bar
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 2, f'{acc:.2f}%', ha='center', va='bottom', fontsize=10)
plt.ylim(0, 100)
plt.tight_layout()
plt.show()



import matplotlib.pyplot as plt
import numpy as np

# Sample data
models = ['Logistic Regression', 'Naive Bayes', 'SVM', 'Random Forest', 'Gradient Boosting', 'RNN', 'CNN', 'BiLSTM', 'CNN+BiLSTM+LR']
before_augmentation = [89, 85, 88, 87, 86, 87, 88, 88, 91.4]  # Accuracy scores before augmentation
after_augmentation = [0.9359259259259259 * 100, 0.90 * 100, 0.93 * 100, 0.93 * 100, 0.89 * 100, 0.9372486772486772 * 100, 0.9225396825396826 * 100, 0.93 * 100, 0.9518 * 100]   # Accuracy scores after augmentation

# Set the width of the bars
bar_width = 0.35
index = np.arange(len(models))

# Increase the figure size
fig, ax = plt.subplots(figsize=(12, 6))  # Adjust the size as needed

# Plot the bars for accuracy before augmentation
bar1 = ax.bar(index - bar_width/2, before_augmentation, bar_width, label='Before Augmentation')

# Plot the bars for accuracy after augmentation
bar2 = ax.bar(index + bar_width/2, after_augmentation, bar_width, label='After Augmentation')

# Add labels, title, and legend
ax.set_xlabel('Models')
ax.set_ylabel('Accuracy')
# ax.set_title('Accuracy Comparison Before and After Augmentation')
ax.set_xticks(index)
ax.set_xticklabels(models, rotation=0)  # Rotate x-axis labels for better readability

# Add values at the top of each bar
for i, bar in enumerate(bar1 + bar2):
    height = bar.get_height()
    ax.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3), textcoords='offset points', ha='center', va='bottom')

# Move the legend outside to the right
ax.legend(loc='lower right', bbox_to_anchor=(1, 1))

# Show the plot
plt.tight_layout()
plt.show()

